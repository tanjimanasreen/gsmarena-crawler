{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"gsmarena_bs4_scraper.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"10KzmxOT6dk2F9UnvouTP_zzhhiEgIRlN","authorship_tag":"ABX9TyMrr1RJJrduShWPc5FNp4PK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"TnPw1bVOnwr8"},"source":["### Scraping Gsmarena.com.bd using BeautifulSoup\n","\n","---\n","##### Required Libraries\n"]},{"cell_type":"code","metadata":{"id":"-E4W51UGm1XW"},"source":["import pandas as pd\n","import requests\n","from bs4 import BeautifulSoup\n","import json\n","import unicodedata\n","import re\n","import time\n","import timeit\n","import datetime\n","\n","headers = {'authority': 'www.gsmarena.com.bd',\n","        'pragma': 'no-cache',\n","        'cache-control': 'no-cache',\n","        'dnt': '1',\n","        'upgrade-insecure-requests': '1',\n","        'user-agent': 'Mozilla/5.0 (X11; CrOS x86_64 8172.45.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.64 Safari/537.36',\n","        'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n","        'sec-fetch-site': 'none',\n","        'sec-fetch-mode': 'navigate',\n","        'sec-fetch-dest': 'document',\n","        'accept-language': 'en-GB,en-US;q=0.9,en;q=0.8',}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6drcMYi_n_gV"},"source":["### Function Definitions\n","\n","---\n","1. **``` get_brands()```** returns a list of all the brands' urls.\n","2. **``` get_products_link```** takes the url of a particular brand and returns all the phones' urls.\n","3. **``` get_products_spec```** takes a list of phones' urls and returns a list of all the phones' specifications.\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"dt3hDao4n-Ok"},"source":["# Get the Brands Urls\n","def get_brands():\n","  url = \"https://www.gsmarena.com.bd/brands/\"\n","  try:\n","    req = requests.get(url, headers=headers)\n","    soup = BeautifulSoup(req.text, 'html.parser')\n","\n","    brand_page = soup.select('div.product-thumb div.image a')\n","    brand_list = []\n","\n","    for b in brand_page:\n","      brand_list.append(b.get(\"href\"))\n","\n","  except AttributeError as e:\n","    print(e)\n","\n","  return brand_list\n","\n","\n","# Get all the Phones' Urls\n","def get_products_link(url):\n","  url = url\n","  product = []\n","  while True:\n","    req = requests.get(url, headers=headers)\n","    soup = BeautifulSoup(req.text, 'html.parser')\n","\n","    link_find = soup.select('div.product-thumb a')\n","\n","    list_link = []\n","    for l in link_find:\n","      list_link.append(l.get(\"href\"))\n","    \n","    product.extend(list_link)\n","\n","    # Pagination\n","    try:\n","      if soup.select(\"ul.pagination\"):\n","        page = soup.select(\"ul.pagination li a\")\n","        url = page[-1].get(\"href\")\n","\n","        if url == \"#\":\n","          break\n","      else:\n","        break\n","    except AttributeError as e:\n","      print(e)\n","\t\t  \n","  return product\n","\n","\n","# Get the Specifications of all the phones'\n","def get_products_spec(all_product_link):\n","  product_count = 1\n","  discarded_count = 1\n","  all_product = []\n","  for link in all_product_link:\n","    try:\n","      req = requests.get(link, headers=headers)\n","      soup = BeautifulSoup(req.text, 'html.parser')\n","      spec = {}\n","      for table in soup.find_all('table','table table-striped'):\n","        temp = \"\"\n","        for t in table:\n","          head = unicodedata.normalize('NFKD', t.th.text)\n","          body = unicodedata.normalize('NFKD', t.td.text).strip()\n","          \n","          # Checking if the specification belongs to the previous category\n","          if head.isspace():\n","            head = temp\n","            if isinstance(spec[temp], list):\n","              spec[head].append(body)\n","            else:\n","              spec[temp]= [spec[temp]]\n","              spec[head].append(body)  \n","          else:\n","            #head = head.strip()\n","            spec[head] = body\n","          temp = head\n","\n","      # Removing Smart Watches and Feature Phones (Non-Smart Phones) from the list\n","      if spec['Category'].lower() ==  'smart watch':\n","        print(\"Smart Watch: \", discarded_count)\n","        discarded_count = discarded_count + 1\n","      elif spec['Category'].lower() == 'feature phone':\n","        print(\"Feature phone Discarged: \", discarded_count)\n","        discarded_count = discarded_count + 1\n","      else:\n","        spec[\"url\"] = link\n","        all_product.append(spec)\n","        print(product_count)\n","        product_count = product_count + 1\n","\n","    except  AttributeError as e:\n","      print(e)\n","\n","  return all_product\n","\n","\n","start = timeit.default_timer()\n","\n","brands = get_brands()\n","all_product_link = []\n","for brand in brands:\n","  all_product_link.extend(get_products_link(brand))\n","\n","all_product = get_products_spec(all_product_link)\n","\n","# Storing the specifications in a json file\n","with open('all_product_spec_06_09_21.json', 'w') as outfile:\n","    json.dump(all_product, outfile, indent = 4)\n","\n","stop = timeit.default_timer()\n","print('Time: ', stop - start)"],"execution_count":null,"outputs":[]}]}